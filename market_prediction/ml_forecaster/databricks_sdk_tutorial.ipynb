{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff39f38-2c70-43ab-b588-5537f7a26f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958910f4-24f5-46c1-85a8-dd6e5f3fb4aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceAlreadyExists",
     "evalue": "Node named 'my-experiment55' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceAlreadyExists\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- 1) Create an experiment ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m exp = \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/feldmanngreg@gmail.com/my-experiment55\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m exp_id = exp.experiment_id\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExperiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\data_science\\standard_env\\Lib\\site-packages\\databricks\\sdk\\service\\ml.py:5037\u001b[39m, in \u001b[36mExperimentsAPI.create_experiment\u001b[39m\u001b[34m(self, name, artifact_location, tags)\u001b[39m\n\u001b[32m   5031\u001b[39m     body[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] = [v.as_dict() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m tags]\n\u001b[32m   5032\u001b[39m headers = {\n\u001b[32m   5033\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5034\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5035\u001b[39m }\n\u001b[32m-> \u001b[39m\u001b[32m5037\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/api/2.0/mlflow/experiments/create\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5038\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CreateExperimentResponse.from_dict(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\data_science\\standard_env\\Lib\\site-packages\\databricks\\sdk\\core.py:85\u001b[39m, in \u001b[36mApiClient.do\u001b[39m\u001b[34m(self, method, path, url, query, headers, body, raw, files, data, auth, response_headers)\u001b[39m\n\u001b[32m     83\u001b[39m     path = re.sub(\u001b[33m\"\u001b[39m\u001b[33m^/api/2.0/fs/files//\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m/api/2.0/fs/files/\u001b[39m\u001b[33m\"\u001b[39m, path)\n\u001b[32m     84\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._cfg.host\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\data_science\\standard_env\\Lib\\site-packages\\databricks\\sdk\\_base_client.py:196\u001b[39m, in \u001b[36m_BaseClient.do\u001b[39m\u001b[34m(self, method, url, query, headers, body, raw, files, data, auth, response_headers)\u001b[39m\n\u001b[32m    193\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetry disabled for non-seekable stream: type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m     call = \u001b[38;5;28mself\u001b[39m._perform\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m response = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m resp = \u001b[38;5;28mdict\u001b[39m()\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m header \u001b[38;5;129;01min\u001b[39;00m response_headers \u001b[38;5;28;01mif\u001b[39;00m response_headers \u001b[38;5;28;01melse\u001b[39;00m []:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\data_science\\standard_env\\Lib\\site-packages\\databricks\\sdk\\retries.py:57\u001b[39m, in \u001b[36mretried.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m         retry_reason = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(err).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is allowed to retry\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retry_reason \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# raise if exception is not retryable\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     59\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrying: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (sleeping ~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m before_retry:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\data_science\\standard_env\\Lib\\site-packages\\databricks\\sdk\\retries.py:36\u001b[39m, in \u001b[36mretried.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m clock.time() < deadline:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     38\u001b[39m         last_err = err\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\data_science\\standard_env\\Lib\\site-packages\\databricks\\sdk\\_base_client.py:298\u001b[39m, in \u001b[36m_BaseClient._perform\u001b[39m\u001b[34m(self, method, url, query, headers, body, raw, files, data, auth)\u001b[39m\n\u001b[32m    296\u001b[39m error = \u001b[38;5;28mself\u001b[39m._error_parser.get_api_error(response)\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mResourceAlreadyExists\u001b[39m: Node named 'my-experiment55' already exists"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import uuid\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import ml\n",
    "\n",
    "# --- 1) Create an experiment ---\n",
    "exp = w.experiments.create_experiment(name=\"/Users/feldmanngreg@gmail.com/my-experiment55\")\n",
    "exp_id = exp.experiment_id\n",
    "print(f\"Experiment: {exp_id}\")\n",
    "\n",
    "# --- 2) Create a run with optional tags ---\n",
    "run = w.experiments.create_run(\n",
    "    experiment_id=exp_id,\n",
    "    run_name=\"hello-sdk-MOOO_MOO_MOO\"\n",
    ")\n",
    "run_id = run.run.info.run_id\n",
    "print(f\"Created run: {run_id}\")\n",
    "\n",
    "# --- 3) Log params and metrics in a single batch ---\n",
    "now_ms = int(time.time() * 1000)\n",
    "w.experiments.log_batch(\n",
    "    run_id=run_id,\n",
    "    params=[\n",
    "        ml.Param(key=\"framework\", value=\"sklearn\"),\n",
    "        ml.Param(key=\"n_estimators\", value=\"200\")\n",
    "    ],\n",
    "    metrics=[\n",
    "        ml.Metric(key=\"accuracy\", value=0.95, timestamp=now_ms, step=0)\n",
    "    ]\n",
    ")\n",
    "print(\"Logged params/metrics.\")\n",
    "\n",
    "# --- 4) Create a logged model tied to that run ---\n",
    "resp = w.experiments.create_logged_model(\n",
    "    experiment_id=exp_id,\n",
    "    source_run_id=run_id,\n",
    "    model_type=\"Classifier\",\n",
    "    name=\"hello-sdk-model\",\n",
    "    params=[\n",
    "        ml.LoggedModelParameter(key=\"framework\", value=\"sklearn\"),\n",
    "        ml.LoggedModelParameter(key=\"n_estimators\", value=\"200\"),\n",
    "    ],\n",
    "    tags=[\n",
    "        ml.LoggedModelTag(key=\"owner\", value=\"feldmanngreg@gmail.com\"),\n",
    "        ml.LoggedModelTag(key=\"env\", value=\"dev\"),\n",
    "    ]\n",
    ")\n",
    "print(\"CreateLoggedModelResponse:\", resp)\n",
    "\n",
    "# --- 5) Read the run back (includes latest metrics/params/tags) ---\n",
    "got = w.experiments.get_run(run_id=run_id)\n",
    "print(\"Params:\", {p.key: p.value for p in got.run.data.params})\n",
    "print(\"Metrics:\", {m.key: m.value for m in got.run.data.metrics})\n",
    "print(\"Tags:\", {t.key: t.value for t in got.run.data.tags})\n",
    "\n",
    "# --- 6) Cleanup (optional) ---\n",
    "# w.experiments.delete_run(run_id=run_id)\n",
    "# w.experiments.delete_experiment(experiment_id=exp_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae24488-1327-437f-9a50-b961db1de558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT: main\n",
      "CAT: samples\n",
      "CAT: system\n",
      "CAT: workspace\n"
     ]
    }
   ],
   "source": [
    "# List catalogs\n",
    "for cat in w.catalogs.list():\n",
    "    print(\"CAT:\", cat.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9003b1d4-29cb-4567-bc2f-7fa91c0a8a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCH: workspace.default\n",
      "SCH: workspace.information_schema\n"
     ]
    }
   ],
   "source": [
    "# List schemas in a catalog\n",
    "for sch in w.schemas.list(catalog_name=\"workspace\"):\n",
    "    print(\"SCH:\", sch.full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc148d41-8e63-4fa1-a9b9-aa41b81d97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL: workspace.default.aapl_market_price\n"
     ]
    }
   ],
   "source": [
    "# List tables in a schema\n",
    "for t in w.tables.list(catalog_name=\"workspace\", schema_name=\"default\"):\n",
    "    print(\"TBL:\", t.full_name)  # e.g. samples.nyctaxi.trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43fecc2d-eceb-481e-9f8c-74491c30cb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableType.MANAGED DataSourceFormat.DELTA\n"
     ]
    }
   ],
   "source": [
    "# Inspect a specific table\n",
    "t = w.tables.get(\"workspace.default.aapl_market_price\")\n",
    "print(t.table_type, t.data_source_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2299df3b-4c99-4f1f-8b8a-491101238f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace.default.aapl_market_price TableType.MANAGED DataSourceFormat.DELTA\n",
      "Using warehouse: Serverless Starter Warehouse (fe0c99db2c996651)\n"
     ]
    }
   ],
   "source": [
    "# You already have this:\n",
    "t = w.tables.get(\"workspace.default.aapl_market_price\")\n",
    "print(t.full_name, t.table_type, t.data_source_format)  # sanity check\n",
    "\n",
    "# Pick a SQL Warehouse (or set warehouse_id = \"...your warehouse id...\")\n",
    "warehouse = next(iter(w.warehouses.list()))\n",
    "warehouse_id = warehouse.id\n",
    "print(f\"Using warehouse: {warehouse.name} ({warehouse_id})\")\n",
    "\n",
    "# Build a query (fully qualified name from t.full_name)\n",
    "sql = f\"\"\"\n",
    "SELECT CAST(date AS DATE) AS date, adj_close\n",
    "FROM {t.full_name}\n",
    "ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "# Execute via Statement Execution API\n",
    "stmt = w.statement_execution.execute_statement(\n",
    "    statement=sql,\n",
    "    warehouse_id=warehouse_id,\n",
    "    # Optional context (not required since we used full_name):\n",
    "    catalog=t.catalog_name,\n",
    "    schema=t.schema_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a76c34-cf9a-47d6-b831-551dd4afc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using warehouse: Serverless Starter Warehouse (fe0c99db2c996651); state=State.RUNNING\n",
      "Name: Serverless Starter Warehouse, ID: fe0c99db2c996651\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DATABRICKS_CONFIG_PROFILE\"] = \"C:/Users/feldm\"\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.sql import ExecuteStatementRequestOnWaitTimeout\n",
    "from databricks.sdk.service import ml\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "w = WorkspaceClient(profile=\"DEFAULT\", config_file=\"C:/Users/feldm/.databrickscfg\")\n",
    "\n",
    "# --- Pick a warehouse (or set warehouse_id = \"...\") ---\n",
    "warehouse = next(iter(w.warehouses.list()))\n",
    "warehouse_id = warehouse.id\n",
    "print(f\"Using warehouse: {warehouse.name} ({warehouse_id}); state={warehouse.state}\")\n",
    "\n",
    "# --- Get the table and build SQL ---\n",
    "t = w.tables.get(\"workspace.default.aapl_market_price\")\n",
    "\n",
    "warehouses = w.warehouses.list()\n",
    "for warehouse in warehouses:\n",
    "    print(f\"Name: {warehouse.name}, ID: {warehouse.id}\")\n",
    "\n",
    "response = w.statement_execution.execute_statement(\n",
    "    statement=f\"SELECT * FROM {t.catalog_name}.{t.schema_name}.aapl_market_price\",\n",
    "    warehouse_id=warehouse.id,\n",
    "    wait_timeout=\"30s\",  # Wait up to 30 seconds\n",
    "    on_wait_timeout=ExecuteStatementRequestOnWaitTimeout.CANCEL  # Cancel if timeout\n",
    ")\n",
    "if response.status.state == \"SUCCEEDED\":\n",
    "    print(\"Results:\", response.result.data)  # Access the data\n",
    "\n",
    "column_names = [col.name for col in response.manifest.schema.columns]\n",
    "df = pd.DataFrame(response.result.data_array, columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf4fba-4ef4-41a4-9f4f-f2dc1a91c0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
