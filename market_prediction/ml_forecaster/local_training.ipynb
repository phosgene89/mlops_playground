{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cebc88-4929-40ba-bc87-955d60d3ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DATABRICKS_CONFIG_PROFILE\"] = \"C:/Users/feldm\"\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.sql import ExecuteStatementRequestOnWaitTimeout\n",
    "from databricks.sdk.service import ml\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "464f7490-4d97-4e19-8972-670e85ff7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_data(workspace_client):\n",
    "\n",
    "    warehouse = w.warehouses.list()[0]\n",
    "    print(f\"Using warehouse: {warehouse.name} ({warehouse.id}); state={warehouse.state}\")\n",
    "    \n",
    "    SCHEMA_NAME = 'default'\n",
    "    CATALOG_NAME = 'workspace'\n",
    "    TABLE_NAME = 'aapl_market_price'\n",
    "    \n",
    "    response = w.statement_execution.execute_statement(\n",
    "        statement=f\"SELECT * FROM {CATALOG_NAME}.{SCHEMA_NAME}.{TABLE_NAME}\",\n",
    "        warehouse_id=warehouse.id,\n",
    "        wait_timeout=\"30s\",\n",
    "        on_wait_timeout=ExecuteStatementRequestOnWaitTimeout.CANCEL  # Cancel if timeout\n",
    "    )\n",
    "    \n",
    "    column_names = [col.name for col in response.manifest.schema.columns]\n",
    "    df_original = pd.DataFrame(response.result.data_array, columns=column_names)\n",
    "\n",
    "    return df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ec628fa-3d2a-4773-8f82-66f083230007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using warehouse: Serverless Starter Warehouse (fe0c99db2c996651); state=State.RUNNING\n"
     ]
    }
   ],
   "source": [
    "w = WorkspaceClient(profile=\"DEFAULT\", config_file=\"C:/Users/feldm/.databrickscfg\")\n",
    "\n",
    "df_original = fetch_historical_data(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b969de2e-97a2-486e-955e-f27650766d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['adj_open', 'adj_high', 'adj_low', 'adj_close', 'adj_volume']:\n",
    "    df_original[col] = df_original[col].astype(float)\n",
    "\n",
    "df_original.drop(['open', 'high', 'low', 'close', 'volume', 'split_factor', 'dividend'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08231eb3-48c1-4eef-b75e-005da72ff80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 2628800825290818\n",
      "Created parent run: 8a225f8022de4136b679bf7787f2ff83\n",
      "Logged initial params to parent run.\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Create an experiment ---\n",
    "exp_name = f\"/Users/feldmanngreg@gmail.com/my-experiment-{uuid.uuid4().hex[:8]}\"  # Unique name\n",
    "exp = w.experiments.create_experiment(name=exp_name)\n",
    "exp_id = exp.experiment_id\n",
    "print(f\"Experiment: {exp_id}\")\n",
    "\n",
    "# --- 2) Create a parent run with optional tags ---\n",
    "parent_run = w.experiments.create_run(\n",
    "    experiment_id=exp_id,\n",
    "    run_name=\"stock-direction-predictor-parent-run\"\n",
    ")\n",
    "parent_run_id = parent_run.run.info.run_id\n",
    "print(f\"Created parent run: {parent_run_id}\")\n",
    "\n",
    "# --- 3) Log initial params in a single batch for parent run ---\n",
    "now_ms = int(time.time() * 1000)\n",
    "w.experiments.log_batch(\n",
    "    run_id=parent_run_id,\n",
    "    params=[\n",
    "        ml.Param(key=\"framework\", value=\"statsmodels\"),\n",
    "        ml.Param(key=\"model_type\", value=\"Logit\"),\n",
    "        ml.Param(key=\"train_test_split\", value=\"0.8\"),\n",
    "        ml.Param(key=\"optuna_trials\", value=\"20\")\n",
    "    ],\n",
    "    metrics=[]  # Metrics will be logged after training\n",
    ")\n",
    "print(\"Logged initial params to parent run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adbfbd3c-9f82-4ba1-b0ee-8519cfae2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optuna objective for hyperparameter search (tuning number of lags)\n",
    "def objective(trial):\n",
    "    lags = trial.suggest_int('lags', 1, 10)  # Tune number of lags\n",
    "\n",
    "    # Create a new run for this trial\n",
    "    trial_run = w.experiments.create_run(\n",
    "        experiment_id=exp_id,\n",
    "        run_name=f\"trial_{trial.number}\"\n",
    "    )\n",
    "    trial_run_id = trial_run.run.info.run_id\n",
    "    print(f\"Created trial run: {trial_run_id}\")\n",
    "\n",
    "    # Log trial params\n",
    "    w.experiments.log_batch(\n",
    "        run_id=trial_run_id,\n",
    "        params=[\n",
    "            ml.Param(key=\"lags\", value=str(lags)),\n",
    "            ml.Param(key=\"framework\", value=\"statsmodels\"),\n",
    "            ml.Param(key=\"model_type\", value=\"Logit\"),\n",
    "            ml.Param(key=\"train_test_split\", value=\"0.8\"),\n",
    "            ml.Param(key=\"optuna_trials\", value=\"20\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Re-generate features with current lags\n",
    "    df = df_original.copy()\n",
    "    for i in range(1, lags + 1):\n",
    "        df[f'lag_{i}'] = df['adj_close'].shift(i)\n",
    "\n",
    "    # Target: Next day's adj_close for comparison\n",
    "    df['target'] = df['adj_close'].shift(-1)\n",
    "\n",
    "    # Binary target: 1 if next adj_close > current adj_close (up), else 0 (down)\n",
    "    df['up_down'] = (df['target'] > df['adj_close']).astype(int)\n",
    "\n",
    "    # Drop rows with NaN (from shifts)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Exogenous features: adj columns + lags (added adj_close as per user update)\n",
    "    features = ['adj_open', 'adj_high', 'adj_low', 'adj_volume', 'adj_close'] + [f'lag_{i}' for i in range(1, lags + 1)]\n",
    "    \n",
    "    # Ensure all features are numeric (redundant if df_raw converted, but safe)\n",
    "    df[features] = df[features].apply(pd.to_numeric, errors='coerce')\n",
    "    df.dropna(inplace=True)  # Drop any coerced NaNs\n",
    "\n",
    "    exog = df[features]\n",
    "    endog = df['up_down']  # Binary endogenous variable\n",
    "\n",
    "    # Split data: Time-series split (80% train, 20% test)\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    exog_train, exog_test = exog.iloc[:train_size], exog.iloc[train_size:]\n",
    "    endog_train, endog_test = endog.iloc[:train_size], endog.iloc[train_size:]\n",
    "\n",
    "    # Train statsmodels Logit\n",
    "    exog_train_const = sm.add_constant(exog_train)\n",
    "    model = sm.Logit(endog_train, exog_train_const)\n",
    "    model_fit = model.fit(disp=False, method='newton', maxiter=1000)  # Fixed method for consistency\n",
    "\n",
    "    # Evaluate on test set\n",
    "    exog_test_const = sm.add_constant(exog_test)\n",
    "    prob_pred = model_fit.predict(exog_test_const)\n",
    "    pred_class = (prob_pred > 0.5).astype(int)\n",
    "    accuracy = (pred_class == endog_test).mean()\n",
    "\n",
    "    # Log trial metric\n",
    "    now_ms = int(time.time() * 1000)\n",
    "    w.experiments.log_batch(\n",
    "        run_id=trial_run_id,\n",
    "        metrics=[\n",
    "            ml.Metric(key=\"accuracy\", value=accuracy, timestamp=now_ms, step=0)\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Logged trial {trial.number} with accuracy: {accuracy}\")\n",
    "\n",
    "    return accuracy  # Maximize accuracy on validation (here test, but for real CV, average folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "992d6146-095f-4b32-a6f6-8acb174cdecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:12,182] A new study created in memory with name: no-name-3bd241f1-047e-419c-85b5-c015f7f51d4e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created trial run: 109757935d7d42c18890e20581a2f7c2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:12,512] Trial 0 finished with value: 0.52690084481992 and parameters: {'lags': 6}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 0 with accuracy: 0.52690084481992\n",
      "Created trial run: 2c5f3cae2798433b9b29b69787fa2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:12,869] Trial 1 finished with value: 0.5253333333333333 and parameters: {'lags': 2}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 1 with accuracy: 0.5253333333333333\n",
      "Created trial run: 33202162dd6642dd8f3c0bca3ae2cb94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:13,176] Trial 2 finished with value: 0.5257777777777778 and parameters: {'lags': 1}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 2 with accuracy: 0.5257777777777778\n",
      "Created trial run: 99a2114d7585410ba3d38a67af65f77e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:13,490] Trial 3 finished with value: 0.5253333333333333 and parameters: {'lags': 2}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 3 with accuracy: 0.5253333333333333\n",
      "Created trial run: 8ebc5e9e8d8f469eabb9f1114b1952e7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:13,808] Trial 4 finished with value: 0.5264562027567808 and parameters: {'lags': 7}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 4 with accuracy: 0.5264562027567808\n",
      "Created trial run: 599b04d3e1254518a3f58eeb01373f3a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:14,124] Trial 5 finished with value: 0.5262455516014235 and parameters: {'lags': 9}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 5 with accuracy: 0.5262455516014235\n",
      "Created trial run: 7ef06a9bc09b44e4bbf8dcdb5e9b5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:14,463] Trial 6 finished with value: 0.5258007117437722 and parameters: {'lags': 8}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 6 with accuracy: 0.5258007117437722\n",
      "Created trial run: 60cf85f5dfeb420696ebe786cd77ad54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:14,777] Trial 7 finished with value: 0.5264562027567808 and parameters: {'lags': 5}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 7 with accuracy: 0.5264562027567808\n",
      "Created trial run: fab3b3cf2a444289855ec080b7aa4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:15,085] Trial 8 finished with value: 0.52690084481992 and parameters: {'lags': 6}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 8 with accuracy: 0.52690084481992\n",
      "Created trial run: c6721d24550d4e48ad7e65f6dd720c33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:15,395] Trial 9 finished with value: 0.5251222765673633 and parameters: {'lags': 4}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 9 with accuracy: 0.5251222765673633\n",
      "Created trial run: 850413e4de4a4f2ba60776050ad18df7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:15,723] Trial 10 finished with value: 0.5258007117437722 and parameters: {'lags': 10}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 10 with accuracy: 0.5258007117437722\n",
      "Created trial run: 72e9df773e24419e98d6c39c9445a605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:16,060] Trial 11 finished with value: 0.52690084481992 and parameters: {'lags': 6}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 11 with accuracy: 0.52690084481992\n",
      "Created trial run: 28520015bb8443e6a9ba0d0f277ed990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:16,377] Trial 12 finished with value: 0.5251222765673633 and parameters: {'lags': 4}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 12 with accuracy: 0.5251222765673633\n",
      "Created trial run: cf00b90d69a040a2b0cc44594049add1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:16,692] Trial 13 finished with value: 0.52690084481992 and parameters: {'lags': 6}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 13 with accuracy: 0.52690084481992\n",
      "Created trial run: fdabae70bd0e43beb5d2f8e2cd554218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:17,015] Trial 14 finished with value: 0.5264562027567808 and parameters: {'lags': 7}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 14 with accuracy: 0.5264562027567808\n",
      "Created trial run: 370079d67ae7456f933499067e44d872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:17,343] Trial 15 finished with value: 0.5251222765673633 and parameters: {'lags': 4}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 15 with accuracy: 0.5251222765673633\n",
      "Created trial run: 4b7df322921f48008727b4c835c14bd1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:17,660] Trial 16 finished with value: 0.5258007117437722 and parameters: {'lags': 8}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 16 with accuracy: 0.5258007117437722\n",
      "Created trial run: 4f09c72708064b1da686d89c977b68c8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:17,982] Trial 17 finished with value: 0.5264562027567808 and parameters: {'lags': 5}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 17 with accuracy: 0.5264562027567808\n",
      "Created trial run: 7f0f38a4133d4380a90dae332f3fd6cc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:18,299] Trial 18 finished with value: 0.5264562027567808 and parameters: {'lags': 7}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 18 with accuracy: 0.5264562027567808\n",
      "Created trial run: 72d8c1c01e1b4e61811821a102706c7f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 15:24:18,615] Trial 19 finished with value: 0.5246776345042241 and parameters: {'lags': 3}. Best is trial 0 with value: 0.52690084481992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged trial 19 with accuracy: 0.5246776345042241\n",
      "Best params: {'lags': 6}\n",
      "Best accuracy: 0.52690084481992\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  # Adjust n_trials as needed\n",
    "\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f'Best params: {best_params}')\n",
    "print(f'Best accuracy: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d441a99-f96e-4e43-8c9b-dca71f3034e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.52690084481992\n",
      "Logged metrics and best params.\n",
      "CreateLoggedModelResponse: CreateLoggedModelResponse(model=LoggedModel(data=LoggedModelData(metrics=[], params=[LoggedModelParameter(key='framework', value='statsmodels'), LoggedModelParameter(key='lags', value='6')]), info=LoggedModelInfo(artifact_uri='dbfs:/databricks/mlflow-tracking/2628800825290818/logged_models/m-3e3dd428b87c48ecab44de803e285734/artifacts', creation_timestamp_ms=1755410063632, creator_id=76055929257863, experiment_id='2628800825290818', last_updated_timestamp_ms=1755410063637, model_id='m-3e3dd428b87c48ecab44de803e285734', model_type='Classifier', name='stock-direction-model', source_run_id='8a225f8022de4136b679bf7787f2ff83', status=<LoggedModelStatus.LOGGED_MODEL_PENDING: 'LOGGED_MODEL_PENDING'>, status_message=None, tags=[LoggedModelTag(key='env', value='dev'), LoggedModelTag(key='mlflow.loggedModel.artifactLocation', value='dbfs:/databricks/mlflow-tracking/2628800825290818/logged_models/m-3e3dd428b87c48ecab44de803e285734/artifacts'), LoggedModelTag(key='mlflow.loggedModel.name', value='stock-direction-model'), LoggedModelTag(key='owner', value='feldmanngreg@gmail.com'), LoggedModelTag(key='mlflow.user', value='feldmanngreg@gmail.com')])))\n",
      "Params: {'framework': 'statsmodels', 'lags': '6', 'model_type': 'Logit', 'optuna_trials': '20', 'train_test_split': '0.8'}\n",
      "Metrics: {'optuna_best_accuracy': 0.52690084481992, 'test_accuracy': 0.52690084481992}\n",
      "Tags: {'mlflow.runColor': '#5387dd', 'mlflow.runName': 'stock-direction-predictor-parent-run', 'mlflow.user': 'feldmanngreg@gmail.com'}\n"
     ]
    }
   ],
   "source": [
    "# Re-train final model with best params (best lags)\n",
    "lags = best_params['lags']\n",
    "df = df_original.copy()  # Assuming df_original is df_raw\n",
    "for i in range(1, lags + 1):\n",
    "    df[f'lag_{i}'] = df['adj_close'].shift(i)\n",
    "df['target'] = df['adj_close'].shift(-1)\n",
    "df['up_down'] = (df['target'] > df['adj_close']).astype(int)\n",
    "df.dropna(inplace=True)\n",
    "features = ['adj_open', 'adj_high', 'adj_low', 'adj_volume', 'adj_close'] + [f'lag_{i}' for i in range(1, lags + 1)]\n",
    "exog = df[features]\n",
    "endog = df['up_down']\n",
    "train_size = int(len(df) * 0.8)\n",
    "exog_train, exog_test = exog.iloc[:train_size], exog.iloc[train_size:]\n",
    "endog_train, endog_test = endog.iloc[:train_size], endog.iloc[train_size:]\n",
    "exog_train_const = sm.add_constant(exog_train)\n",
    "model = sm.Logit(endog_train, exog_train_const)\n",
    "model_fit = model.fit(disp=False)\n",
    "exog_test_const = sm.add_constant(exog_test)\n",
    "prob_pred = model_fit.predict(exog_test_const)\n",
    "pred_class = (prob_pred > 0.5).astype(int)\n",
    "accuracy = (pred_class == endog_test).mean()\n",
    "print(f'Accuracy on test set: {accuracy}')\n",
    "# Log metrics and best params after training\n",
    "log_params = [ml.Param(key=k, value=str(v)) for k, v in best_params.items()]\n",
    "now_ms = int(time.time() * 1000)\n",
    "w.experiments.log_batch(\n",
    "    run_id=parent_run_id,\n",
    "    params=log_params,\n",
    "    metrics=[\n",
    "        ml.Metric(key=\"optuna_best_accuracy\", value=best_accuracy, timestamp=now_ms, step=0),\n",
    "        ml.Metric(key=\"test_accuracy\", value=accuracy, timestamp=now_ms, step=0)\n",
    "    ]\n",
    ")\n",
    "print(\"Logged metrics and best params.\")\n",
    "# --- 4) Create a logged model tied to that run ---\n",
    "logged_model_params = [ml.LoggedModelParameter(key=k, value=str(v)) for k, v in best_params.items()]\n",
    "resp = w.experiments.create_logged_model(\n",
    "    experiment_id=exp_id,\n",
    "    source_run_id=parent_run_id,\n",
    "    model_type=\"Classifier\",\n",
    "    name=\"stock-direction-model\",\n",
    "    params=logged_model_params + [\n",
    "        ml.LoggedModelParameter(key=\"framework\", value=\"statsmodels\"),\n",
    "    ],\n",
    "    tags=[\n",
    "        ml.LoggedModelTag(key=\"owner\", value=\"feldmanngreg@gmail.com\"),\n",
    "        ml.LoggedModelTag(key=\"env\", value=\"dev\"),\n",
    "    ]\n",
    ")\n",
    "print(\"CreateLoggedModelResponse:\", resp)\n",
    "# --- 5) Read the run back (includes latest metrics/params/tags) ---\n",
    "got = w.experiments.get_run(run_id=parent_run_id)\n",
    "print(\"Params:\", {p.key: p.value for p in got.run.data.params})\n",
    "print(\"Metrics:\", {m.key: m.value for m in got.run.data.metrics})\n",
    "print(\"Tags:\", {t.key: t.value for t in got.run.data.tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0d4d1-84c7-46a0-bb93-de0e32fa85c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
